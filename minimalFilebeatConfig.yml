###################### Filebeat Configuration Example #########################

# This file is an example configuration file highlighting only the most common
# options. The filebeat.reference.yml file from the same directory contains all the
# supported options with more comments. You can use it as a reference.
#
# You can find the full configuration reference here:
# https://www.elastic.co/guide/en/beats/filebeat/index.html

# For more available modules and options, please see the filebeat.reference.yml sample
# configuration file.

#=========================== Filebeat inputs =============================

filebeat.inputs:

  # Each - is an input. Most options can be set at the input level, so
  # you can use different inputs for various configurations.
  # Below are the input specific configurations.

  #logs from build jobs
  - type: log
    enabled: true
    paths:
      - /mnt/jenkins_home/jobs/*/builds/*/log

  # logs from slaves
  - type: log
    enabled: true
    paths:
      - /var/jenkins_home/logs/slaves/*/slave.log
      -
#TODO Jenkins master log


fields:
  protocol: "${PROTOCOL}"
  master: "${MASTER}"
  domain: "${DOMAIN}"

#============================= Filebeat modules ===============================

filebeat.config.modules:
  # Glob pattern for configuration loading
  path: ${path.config}/modules.d/*.yml

  # Set to true to enable config reloading
  reload.enabled: false

  # Period on which files under path should be checked for changes
  #reload.period: 10s

#==================== Elasticsearch template setting ==========================

setup.template.settings:
  index.number_of_shards: 1
  #index.codec: best_compression
  #_source.enabled: false


#================================ Outputs =====================================

# Configure what output to use when sending the data collected by the beat.

#-------------------------- Elasticsearch output ------------------------------
#output.elasticsearch:
#  # Array of hosts to connect to.
#  hosts: ["mariuskeppler.de:9200"]

output.kafka:
  # initial brokers for reading cluster metadata
  hosts: ["kafka:9092"]

  # message topic selection + partitioning
  topic: 'filebeat-1'
  partition.round_robin:
    reachable_only: false

  required_acks: 1
  compression: gzip
  max_message_bytes: 1000000

#================================ Processors =====================================

# Configure processors to enhance or manipulate events generated by the beat.

processors:
  - add_host_metadata: ~
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~